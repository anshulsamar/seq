Sequence to Sequence RNN LSTM model with variational autoencoding. Built based on the following code/models:
- 'Sequence to Sequence Learning with Neural Networks' (Sutskever, et al. 2014)
- 'Stochastic Gradient Variational Bayes' (Kingma and Welling, 2014)
- Wojzaremba's LSTM and LM code (github.com/wojzaremba/lstm)

Applications include sentence embeddings and machine translation. SGVB is currently only implemented for the autoencoding setting. 